---
title: |
  Does Color Convey Political Information?
short-title: Color as Political Information
published: "Manuscript draft: please do not share without author permission."
code-repo: "For replication, go to: <https:://github.com/DamonCharlesRoberts/book_project>."
author:
  - name: Damon C. Roberts
    email: damon.roberts-1@colorado.edu
    orcid: 0000-0002-4360-3675
    title: PhD Candidate
    affiliations:
      - id: CU
        name: University of Colorado Boulder
        department: Political Science
        address: 333 UCB
        city: Boulder
        region: CO 
        postal-code: 80309-0333
abstract: |
  Do the colors red and blue convey political information? While decisions of political branding are assumed to be significant for electoral outcomes, we have few theories about the cognitive processes underlying the processing of such information and whether these decisions influence realized political behavior. Building upon interdisciplinary perspectives, this chapter introduces the snap-judgment model of visual political information processing. The theory argues that color allows individuals to form pre-cognitive attitudes of a political object and that these pre-cognitive attitudes shape latter and more cognitively laborious information processing and behavior. Meaning, that we can activate partisan attachments automatically through information as simple as color. In the first study, I talk to a political marketing firm and use a pixel-by-pixel classification of images from over 1000 yard signs for elections in the U.S. House of Representatives. Evidence suggests that in districts where Democrats have an electoral advantage, there is more blue on the yard signs in the district. To examine the cognitive processes, I use a novel experimental design by tracking cursor movements and limiting participant's ability to view a yard sign to only 5000ms. I find that participants do make these associations when features of the yard sign are held constant and find that Republicans prefer candidates with red yard signs and that Democrats prefer candidates with blue yard signs.
additional-info: |
  I have no known conflict of interest to disclose.
keywords:
  - visual information
  - information processing
  - partisanship
date: today
bibliography: "../../assets/candidate_support_chapter_references.bib"
format:
  hikmah-pdf:
    cite-method: citeproc
    latex-output-dir: ../out/
    geometry:
      - top=1in
      - bottom=1in
      - left=1in
      - right=1in
      - heightrounded
    linestretch: 2
    fontsize: 12pt
    appendix-style: default
    include-in-header:
      text: |
        \usepackage{pdflscape}
        \newcommand{\blandscape}{\begin{landscape}}
        \newcommand{\elandscape}{\end{landscape}}
linestretch: 2
execute:
  echo: false
  warning: false
  message: false
params:
  replicate: false
---

{{< pagebreak >}}

```{r}
#| label: r-setup-block

# Load some handy functions
box::use(
    data.table[...]
    , modelsummary[
        datasummary_skim
        , datasummary_balance
    ]
    , ./R/predicted_prob_bar[...]
)

# Execute the cleaning script
source("./eda/study_1/cleaning.R")
# Load fitted models
load("../data/temp/models/study_1_fitted.RData")
```

## Introduction

::: {#fig-party-brand layout-ncol=2}

![Republicans pre-2000](assets/img/rnc_logo_pre-2000.png){#fig-republican}

![Democrats pre-2000](assets/img/dnc_logo_1960.png){#fig-democrat}

![Republicans 2023](assets/img/rnc_logo_2023.png){#fig-republican-post}

![Democrats 2023](assets/img/dnc_logo_2023.png){#fig-democrat-post}

Party logos
:::

Do colors provide political information that shape attitudes among the mass public? There are two goals that I am hoping to achieve in this chapter. The first is to convince the reader that the colors red and blue convey affiliative information. The second is that these connections between colors and political groups can shape political outcomes.

Many understand that colors are influential to shaping attitudes and behaviors in a number of ways. Color theorists and scholars of marketing understand color as having important implications for reactions to a product and resulting consumer behavior. For example, @kuo_impact_2023 demonstrate that hotel rooms that use more "cool colors" (blues, greens, etc.) evoke positive affect for potential customers and that these positive affective responses are predictive of their eventual choice to book the room. Colors mean a varying number of things, however. As a gross, yet intelligible example, yellow sweaters relative to yellow bodily fluids can elicit strong and very different responses.

The role of visuals in politics is receiving more attention among interdisciplinary scholars in fields like communication, political science, and the psychological sciences. While many of these studies examine fascinating but complicated forms of visual information such as symbology [@williams_whats_2022] and visual framing [@grabe_image_2009], we have yet to integrate these interdisciplinary perspectives with existing models of political information processing to understand how these visual forms of information act as cues [see @lilleker_power_2019] but also what the consequences are for political behavior among the mass public.

Building upon descriptive evidence suggesting that Democratic campaigns use the color blue more than Republican campaigns [@williams_whats_2022] and that Republican voters express a preference for red during election season [@schloss_politics_2014], I present a snap-judgment model of politically-relevant visual information processing that outlines the cognitive processes that drive these associations and how those associations drive important political outcomes. I use theories of associative memory and spreading activation [see @collins_spreading-activation_1975] to conceptualize the association of the colors red and blue with Republicans and Democrats as two interconnected nodes. Informed by conceptualizations of these connections as carrying affective information informed by perspectives on biological survival reaching back to Darwin [@ralph_neuroscience_2018], I argue that when these nodes are activated by exposure to these colors in political contexts, other related nodes become active and contain affective information. As partisanship evokes strong affective reactions for many members of the public [@iyengar_affect_2012], this activation elicits an affective reaction. Considering that most visual information and that these processes of association occur pre-cognitively [@ames_impression_2012;@fazio_attitudes_2007;@sander_cambridge_2013], I argue that the elicited affective response to such information can be "transferred" [see @morris_activation_2003;@taber_illusion_2016] to later post-cognitive processing of more traditional forms of political information such as stated policy positions. The implication being that these associations can inform reactions to political information and thus political behavior pre-cognitively.
<!--
This chapter applies the snap-judgment model to a simple case: the use of color on yard signs used by campaigns in elections. I focus on yard signs as they are a common form of campaign marketing and evidence suggests that they can shape individual behavior [@makse_politics_2019] and electoral outcomes [@green_effects_2016]. Additionally, I start by examining the colors red and blue. While there are other colors that may provide political information -- black and white for Black Lives Matter and Blue Lives Matter movements, the overarching goal of this book is to lay the foundation for a larger research agenda in visual political psychology [@bucy_editors_2021]. Without such foundations, we would be jumping into the study of complex cases and circumstances without a firm grasp of how things matter on a more fundamental level. 

Before getting into things, it is worth noting that while there indeed is empirical and experiential evidence suggesting that Republicans use the color red and Democrats use the color blue [@schloss_politics_2014;@williams_whats_2022], there is currently no theoretical framework that explains how these connections happen at the individual level. As a side note, one might find it unsatisfying that I do not address *how* these associations between color and the parties came about. While the connections between Republicans with the color red and Democrats with the color blue seemed to quicken after the 2000 Presidential election (with news networks consistently using those colors in campaign coverage [@elving_color_2014]), it is not clear if this was a deliberate choice, or whether this was yet another symptom of an increasingly polarized public. An undertaking to address the specifics of this part of American political history would likely be a different book project.
-->

To preview, in this chapter I propose two studies to evaluate the claims I make about yard signs. Yard signs are a simple yet effective source of campaign branding for political candidates as they convey information that is often useful for voters' partisanship [@campbell_american_1969]. As yard signs are a simple and static form of campaign advertising, they cannot rely heavily on more complicated forms of information. However, one form of information they rely on and vary in is their color. With these characteristics, yard signs are an ideal candidate both from a design and substantive standpoint. From a design standpoint, as they are static forms of party branding they have fewer moving parts, which helps isolate the effect that color has on shaping attitudes. From a substantive standpoint, while we understand that yard signs matter to campaigns, we have yet to systematically explore more simple design choices such as color.

In [Study 1](#study-1), I find descriptive evidence suggesting that campaigns use the colors red and blue on their yard signs at different rates depending on the success of Republicans and Democrats according to previous election returns. It is unclear, however, whether these patterns are based on elite perceptions of how to communicate partisanship to voters or whether campaigns have successfully identified a cognitive process linking the colors red and blue with Republicans and Democrats. Accordingly, in [Study 2](#study-2), I conduct an online experiment that examines whether the public notice color and whether their attitudes are shaped by the presence of "Republican red" and "Democratic blue" on the yard signs of a political candidate. I find that these associations do exist among the public. Specifically, individuals consistently and strongly associate Republicans with the color red and the Democrats with the color Blue. As a result, partisan individuals' willingness to vote for a candidate can be dramatically different depending on whether the color used in the yard sign aligns with their partisan identification.

While these two studies highlight endogenous processes between campaigns and voters, to be clear, I am not arguing that either of these patterns only one way. In fact, I believe that there is a necessary feedback loop between the parties and their bases of support. Voters support candidates who signal strong allegiance to the party to increase their chances for electoral success [@utych_voter-centric_2020], and the parties are motivated to distinguish themselves [@lee_insecure_2016;@clifford_how_2020] as a result of their high levels of ideological and affective polarization [@dietrich_using_2021;@enders_issues_2021]. I leave teasing out directionality for subsequent analyses.

These findings bring much needed evidence in support of the conventional wisdom that the colors red and blue convey political information. The implication of the theory and these findings are that partisan attachments are automatically activated through things as seemingly simple and ubiquitous as color. These activated partisan attachments then have causal effects for attitude expression and political behavior. Given the existing literature demonstrating low-levels of political engagement among the mass public [see @hibbing_stealth_2002] as well as the current hyper-polarized era [see @iyengar_affect_2012], this chapter's argument and findings suggests that voters need not consume any substantive political information before expressing a willingness to cast a vote for a candidate.

## The role of visual information in politics

A central theme of an edited issue of *The International Journal of Press/Politics* is that visual politics is important, yet understudied [@lilleker_introduction_2019]. Those who are engaged in these questions attribute these challenges to methodological sophistication and the difficult task of interdisciplinary theorizing [@gerodimos_interdisciplinary_2019].

The rise of television consumption changed the focus on particular mediums for political communication scholars [@hall_jamieson_creating_2014]. In a similar way, the rise of image-based social media has set new agendas. For several methodological and disciplinary reasons, the visual aspects of television were of little focus in the literature [@bucy_editors_2021]. However, today news organizations and politicians are responding to the ubiquitous use of image-dominant social media platforms like TikTok and Instagram, by joining and posting on such platforms. Scholars need to make this transition as well, integrating the role of simple visual information into theories of political information (abbreviated as *pip*) and attitude formation.

How does politically-relevant visual information matter to politics? From an evolutionary-biological perspective, visual information has been a common source of information for millions of years -- information that a variety of single-and-multi-cell organisms have relied upon to evaluate their environment [@grabe_image_2009, see Chapter 1 for a useful discussion]. As an ancient biological invention, the human brain is organized around visual information processing. Reflecting on this, many scholars of neuroscience argue that visual information is the fastest form of information processing for humans. For example, even complex visual information, such as the warmth expressed in someone's facial features, is automatically and pre-cognitively processed in only about 33 milliseconds (abbreviated as ms) [@ames_impression_2012].

Approached from a different perspective, as humans are cognitive misers, visual information in the realm of politics provides efficient information to voters about politically-relevant actors and events [@lilleker_power_2019]. Evidence suggests that even simple party branding on yard signs can have an emotional appeal, potentially encouraging a shift in attitudes toward the person who owns the yard sign [@makse_politics_2019]. That is, even branding as simple as yard signs appears to influence the attitudes of people who view them. However, as with all types of party branding, questions remain about individual visual components' contributions.

More simple forms of visual information are likely even more efficient forms of information. In the context of the United States, the "Republican red" and "Democratic blue" is a relatively recent invention, but one that likely has significant import in an era where the parties make efforts to distinguish themselves from each other [@clifford_how_2020], and where voters toe the party line [@utych_voter-centric_2020]. Since the 2000 presidential election, the media have consistently used red on their electoral maps in "horserace" journalism to represent Republicans and blue to represent Democrats [@elving_color_2014]. The supposed consequence is that Democrats now report a preference for the color blue over the color red, and Republicans report a preference for the color red over the color blue [@schloss_politics_2014]. Others have demonstrated the strategic choices that candidates make on branding choices -- including color -- based on the types of information they want to convey to voters, and to distinguish themselves from their rivals [@williams_whats_2022].

In western Europe, voters are likely better at connecting the ideological positioning of a party with the color they use in their branding [@casiraghi_colors_2022]. The ability to do so is strengthened when the party is longer-surviving and more prominent [@casiraghi_colors_2022]. The use of politically-relevant colors activates biases toward pre-existing ideological and partisan preferences among voters in a Spanish sample [@losada_maestre_color_2022]. In the United States, male and female candidates use different colors -- among other things such as fonts -- in their campaign branding to convey distinguishing information about themselves [@williams_whats_2022]. 

What remains unclear is whether these patterns in the United States are meaningful. While political psychologists are increasingly interdisciplinary and rely on insights from fields like neuroscience, it remains relatively unclear whether and how color can convey complex information about politics. Further, it remains unclear whether such a simple type of information has enough efficacy to shape political outcomes such as vote intention. This chapter is a first cut at addressing these open questions.

## Integrating color into a model of political information processing

Existing models of political information processing (abbreviated here as *pip*) primarily focus on complex forms of political information, such as policy positions, communicated verbally or through text. As individuals process visual information pre-cognitively, we might expect that they may form a snap-judgment or the initial appraisal of an object with visual information as opposed to these more complex forms of information that often require more cognitive effort by varying orders of magnitude.

Color and other simple visual information are processed much quicker and occur more frequently than text-based information that may be communicated, for example, through a news article [@mehta_blue_2009]. But as color and other visual information are processed differently, we should also consider their use as political information. As visual information is affectively encoded [@cimbalo_emotionally_1978], it can affect the affective state and the latter processing of more complex information, such as text. The visual information provides a snap-judgment or an impression of the object through faster processing, and activates particular neurological processes that influence subsequent information appraisals [@ames_impression_2012]. This implies that snap-judgments from visual political information may have downstream effects that shape the way in which we engage with traditionally considered forms of political information.

Before expanding upon the role of colors in shaping political attitudes, let me first define an attitude as a concept. An attitude represents an accessible, valanced evaluation of associated prior information and experiences. This conceptualization fits with that of the Object-Evaluations Association Model [@fazio_attitudes_2007]. As opposed to viewing attitudes as a latent collection of memories, this model views attitudes as measurable evaluations of memories. As memories are at the core of an attitude, the association of memories with its evaluative component [see @kensinger_affective_2022] contributes to the perspective that attitudes are affective. This implies that we should be able to measure attitudes, but that such an operationalization requires careful consideration of the context's role in any given measure of an attitude (as they result from memories) [@fazio_attitudes_2007]. In this chapter, I consider color's effect on shaping attitudes about a political object -- a yard sign. As I hold this constant in the chapter, concerns about the variation in what people are thinking about when seeing the color red and blue are less important here, though later chapters grapple with this consideration.

I use a popular conceptualization of attitudes as emerging from accessed associated memories [see @lodge_rationalizing_2013; see also @collins_spreading-activation_1975]. The implication of such a conceptualization is that attitudes may be unstable (though not in a random sense). That is, as attitudes are associative, they manifest slightly differently depending on the associative paths activated [@fazio_attitudes_2007]. The retrieval of relevant memories to the attitude depends on many factors, such as the recency of the event, the similarity of the context, and the importance or salience of the memory [@kahana_laws_2022]. This means that the memories retrieved to contribute to an attitude that is quite variable. However, to understand where that variability comes from, we must understand the deeper processes influencing how information is encoded and later retrieved. This illustrates my need to build upon the reigning models of *pip*. Colors may act as a contextual feature that may lead to variability in how a set of political information may shape attitudes. Let me explain how colors might do this.

Colors are associative and are affectively encoded [@cimbalo_emotionally_1978]. When individuals access a memory, they do not just recall an object, but they may recall visual information, such as the color of an object [@mehta_blue_2009]. Due to these features, colors are processed pre-cognitively [@mehta_blue_2009]. As they are affectively encoded, their associations with particular memories contribute to the evaluative component of the memory. For example, individuals associate colors like red with anger and arousal [@valdez_effects_1994], whereas they associate blue with things like happiness and pleasure [@dandrade_colors_1974]. 

The implication of such a process is that colors are compelling as contextual information that shapes the subsequent processing and integration of "traditional" forms of political information used to construct attitudes. As theories of affect transfer suggest, the affective reactions to our pre-cognitive processing of information persist when we transition to cognitive and post-cognitive states [@morris_activation_2003; see @taber_illusion_2016]. As the preference for a particular color correlates with political attitudes [@schloss_politics_2014], I expect that colors may have a causal influence on post-cognitive expressions of political attitudes.

According to the literature in affective neuroscience, visual information is processed in more than one region of the brain, such as the visual cortex [@goldstein_sensation_2017]. That is, these types of processes do not occur in discrete regions of the brain, as some like to think. As attitudes are associative, components of the brain work as a complex highway connecting different types of information. As a result, the processing of visual information will activate other areas of the brain and will make associated paths "hot." One such area is the amygdala. Neuroscientists believe that as visual information is quickly and pre-cognitively processed, the amygdala takes and appraises it based on the paths it activated; this generates a simple affective response to such information [@winkielman_emotion_2011].

<!--
A less technical description of the processes occurring here might look something like this: once politically-relevant visual information is detected, the retina passes it to the brain. Once there, the brain attempts to classify the visual information by activating networks of neurons associated with the current information. With these activated pathways, the brain also attempts to appraise such information based on quick classification. For attitude formation, this implies that, as memories are affectively encoded [@kensinger_affective_2022], these memories help areas such as the amygdala to appraise the current information.
-->

These fast affective classifications are valanced rather than the more laborious categorization of specific emotions (e.g., anger, anxiety, fear, happiness). What this means is that rather than conceptualizing the affective component of this process in line with the popular conceptualizations in political science, such as affective intelligence theory [@marcus_emotions_2000], I conceptualize affect as a more extensive system -- one that considers emotion a cognitive classification process that occurs after the initial valanced appraisals of an object [@sander_cambridge_2013;@ralph_neuroscience_2018]. That is, emotion -- the complex classification of appraisals -- is a cognitive component of affect. By contrast, the pre-cognitive process of affect occurs first with the simple and automatic valanced classification of an object [@winkielman_emotion_2011;@dror_deconstructing_2017].

The pre-cognitive appraisals of the visual information one encounters encourages particular behavioral and attitudinal motivations [@valentino_election_2011;@ralph_neuroscience_2018]. This has evolutionary roots for survival [@ralph_neuroscience_2018;@parker_blink_2003]. While affective appraisals can lead to complex motivations, such as anxiety leading to motivations for information seeking [@marcus_emotions_2000], affective appraisals are valanced and more automatic [@winkielman_emotion_2011]. These affective appraisals lead to a desire to either retract or engage more with an object [@valentino_election_2011]. The snap-judgment resulting from the automatic processing of politically relevant visual information should likely lead to an affective response that motivates either a desire to engage or disengage further with an object.

While the visual information may encourage a particular immediate reaction to engage or disengage from the other information, subsequent information processing and more cognitive processing adjusts this initial appraisal generated by the snap-judgment [@kensinger_affective_2022]. While subsequent information may amend one's snap-judgment, the snap-judgment nevertheless influences the processing of subsequent information by activating particular paths -- this is later encoded as associated with the object as it converts to a memory [@lodge_rationalizing_2013;@kensinger_affective_2022].

Beyond a motivated backlash effect, the popular application of motivated reasoning to political science finds evidence suggesting that individuals take more time processing information that runs against their pre-existing preferences [@taber_motivated_2006]. The explanation for this is that people are finding ways to come up with counterarguments to such information. Therefore, we may expect that those interacting with visual information from a political party with which they disagree to possibly spend more time looking at those objects.

@fig-theory presents an illustration of the snap-judgment model.

{{< include ../../assets/_theory.qmd >}}

Let me illustrate the snap-judgment model with a common experience for residents of the United States. Say you are driving down a highway. At 65 miles per hour, you are traveling at about 95 feet per second at this speed. You split your attention. You focus your eyes on the conditions of the road in front of you, the cars in front of you, and the rear-view mirror where your kids are either dropping food in the crevice between the seats or trying to grab your attention. Out of the corner of your eye, you see a sign. It is not a road sign because it is not the familiar white or yellow background with black lettering. It is election season. You correctly infer that it is a political yard sign. In this split second, you notice the sign's color and may see a name: Mitch McConnell. You now are racking your brain to think about who that is. If you are politically engaged, you might come to that recognition of the name quickly, or it may take you significantly longer if you are less politically engaged because it is information you do not have to access often [see @kensinger_affective_2022]. You figure out that this is a Republican politician. You may come to this with the help of the fact that every year you have seen yard signs on this stretch of the highway. You know that when you see those red-blue maps pop up on news apps on your phone that the electoral forecasts always represent Republican support with red, and blue for democrats. Once you have figured out who this person is with the help of this other information, you react: "ugh, that guy is too loyal to Trump," or "yeah! He's loyal to Trump." You've expressed a political attitude.

What the snap-judgment model predicts is happening in your head would be the following: as soon as the light bounces off the sign (to produce a particular wavelength) and reaches your eyes, your brain is already trying to make sense of this information. This is a valuable tool for survival that biology has optimized for millions of years [@parker_blink_2003]. Rather than slowly processing the visual information and finding yourself in the jaws of a predator, or processing it quickly but forming the wrong impression and running away from a friend, the brain processes the information quickly and pre-cognitively [@newell_unified_1990]. To make sense of such information, it accesses familiar information similar to what it is currently attempting to process, and it does this for the purposes of efficiency [@kahana_laws_2022]. This means accessing memories that contain valanced information [@kensinger_affective_2022]: should I avoid this, or is it pleasant? Once the brain has finished such processing, it can pass its prediction to your cognitive memory. Once you form a reflex of avoid or approach, this opens up space for your brain to process the more complex information: to take the patterns of the light as shapes that construct symbols and letters. This comes later because this information not only requires access to information about what it *is*, but also about what it *means*. Once you understand what it means, you have the information necessary to evaluate it.

The snap-judgment model predicts that you first process the colors of the yard sign. You access associative memory to figure out what those particular wavelengths represent; red, white, blue? As these colors are associated with different emotional states [see @cimbalo_emotionally_1978] and the resulting behavioral consequences, your brain starts sending signals to the rest of your body to prepare for reaction [see @sander_cambridge_2013;@dror_deconstructing_2017]. You now need to figure out what the rest of that information was. What were the patterns of that light? It appears that there were some white letters on the sign. There was an "E," an "L," and "E," a "C," and a "T." That creates the word "ELECT." Meaning to vote for. There were some more letters on the sign. A name. The full name is "Mitch McConnell." Since it is about politics, it must be a politician named Mitch McConnell. Now imagine the information was the same, but the color was blue. You may take more time to figure out who that Mitch McConnell person is and come to your reaction to seeing the yard sign. This is because without the color red, you are first thinking about Democrats who are named Mitch McConnell. Only when you come up empty on your mental Rolodex do you figure out that it is the Republican Mitch McConnell.

How do you react to the color and then to the name? Social groupings are not simply abstract concepts invented by social psychologists; our neurobiology reflects them. For example, researchers find activation of the anterior insula when we observe an instance of an in-group member outperformed by a member of an out-group [see @zink_neural_2012]. The anterior insula activity is associated with physical and emotional pain, and not just for ourselves but also for others [@adolphs_emotion_2011]. Others have also observed that when perceiving someone as part of a high-status social group, there is an increase in activity in the sensorimotor cortex and supplementary motor area, indicating more activity in the areas of the brain that encourage movement [@zink_know_2008]. Visual information about someone in your social group speeds up processing, is more salient, and demands more attention than visual information about an object outside your social group [@zink_neural_2012].

There is significant evidence supporting the theory that our partisan identification reflects more than just our attitudes about politics, but a social identity [@campbell_american_1969;@mason_uncivil_2018] that guides our attitudes [see @achen_democracy_2016;@white_selling_2014; also @bullock_elite_2011]. As our political attitudes reflect shared views among co-partisans [@pickup_expressive_2020], the congruence between political information and our partisan identification influences our reactions to such political information. This means that the visual information we glean from politics will likely motivate the neurological features of social groups, and explain the resulting behavioral manifestations in response to such information. That information is also likely to be processed at different rates. That is, while visual information carries general affective associations, we should also expect associations between politically-relevant colors with partisan identification.


+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------+
| Hypotheses   | Expectation                                                                                                                                         |
+==============+:===================================================================================================================================================:+
| $H_1$        | People notice color                                                                                                                                 |
+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------+
| $H_2$        | Colors shape perceptions of candidate based on partisan associations                                                                                |
+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------+
| $H_3$        | Candidates using Red are more supported by Republicans; candidates using Blue are more supported by Democrats                                       |
+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------+
| $H_4$        | Republicans spend less time evaluating candidates using Red; Democrats spend less time evaluating candidates using Blue                             |
+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------+
| $H_5$        | Campaigns recognize the importance of color to voters' evaluations of candidates and respond strategically                                          |
+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------+

: Summary of hypotheses {#tbl-hypotheses}

From this discussion, I expect the following: that the average potential voter pays attention to the colors used in campaign branding ($H_{1}$); that colors observed shape perceptions about the person and ideological symbol represented in the branding -- this means that individuals express different levels of preference for receiving more information that is consistent with their preferences ($H_{2}$); that the consistency of information explains more positive perceptions (i.e., simple visual information paired with more complex "traditional" information) ($H_{3}$); positive and consistent information is processed more quickly than negative and inconsistent, negative and consistent, and positive and inconsistent information ($H_{4}$); and finally that campaigns make strategic choices about their branding to attract voters ($H_{5}$) -- this is inline with their primary objective of reelection [@fenno_congressmen_1973;@mayhew_congress_1974]. A summary of these hypotheses is presented in @tbl-hypotheses.

## Study 1

In [Study 1](#study-1) I start with testing $H_5$. Though my focus is on the cognitive mechanisms for individuals, I first wanted to examine whether practitioners of political marketing also perceive that these associations exist and are influential. In some informal conversations that I had with political campaign professionals, it became clear that the descriptive evidence connecting the colors red and blue with Republicans and Democrats is still very much based on instinct rather than empirical evidence.

> There obviously is a strong association with blue and the Democratic Party and red and the Republican Party. We've seen in some of our testing that specifically MAGA red tends to elicit a slightly stronger association with Republicans/conservatives/Trump than other shades. The rest of color spectrum doesn't seem to have as strong an association, though greens and purples tend to read a little more left, the combination of red, white and blue tends to read a little more right, black and white tends to read a little left, black and red tend to read a little more right, etc.

It appears that campaigns recognize that these are not simply patterns that journalists [see @elving_color_2014] and researchers [see @williams_whats_2022] have picked up on, but that they are associations held by voters and campaigns respond accordingly:

> Beyond that, I generally suggest that considering associations with party is generally a good place to start.  For example, if you're running in a Democratic primary and that's the race that's going to most likely decide who ultimately gets elected, then blues are a good place to start. 

In the comments above, we see some qualification that there are other colors which betray ideological positions. Still, a potential implication is that the value of colors associated with a particular place can be a way for candidates to communicate attachment to a district and its constituents. Still, there is a preference for campaigns to use as few colors as possible to save on costs -- simpler is better. What particularly stood out was:

> You want voters to be able to look at whatever collateral you have, including lawn signs, and be able to identify that it's your material without ever having to read it. If you do one thing long enough, voters tend to start to associate specific color schemes with specific candidates.

So, unsurprisingly, campaigns care about how they market themselves. And it seems as though campaigns want to tap into quick and efficient information processing for voters and potential voters. However, as also noted during the conversation:

> A lot of decisions are still made on purely gut feelings as opposed to taking a more multi-disciplinary evidence-based approach.

Though it appears that at least one consulting firm of campaign marketing professionals recognize the potential value of using the colors red and blue to cue to the partisanship of a candidate, there is still significant uncertainty about how widespread these patterns are with political campaigns in the United States and whether voters actually do make these associations. The first piece of empirical evidence in this chapter examines whether we observe systematic patterns between campaigns in the use of the colors red and blue on their yard signs. [Study 2](#study-2) then takes my predictions from the snap-judgment model to examine whether these associations exist among voters and what the consequences are.

To gather evidence generalizing the belief that campaigns strategically use the colors red and blue to tap into possible associations of these colors with partisanship, I began by collecting data from the MIT Election Lab that reports the electoral results of the House of Representative elections from the years 1970-2020. The data report the number of votes for each candidate in any given race. With these data, I calculate the rolling 5-year average of the Democratic party's vote share for each district to account for particularly unique electoral events.

Next, I use a combination of HTML and XML tags to identify then download around 1,000 yard signs from House elections from the years 2016 to 2022 from the website provided by the Center for American Politics and Design. I used the `OpenCV` library in `Python` to examine the proportion of the colors near the "Republican red"^[lower RGB values: 93, 9, 12; upper RGB values: 236, 69, 75] and "Democratic blue"^[lower RGB values: 0, 18, 26; upper RGB values [102, 212, 255]] in each of these yard signs.

This approach to measure of the proportion of the Republican red and Democrat blue colors takes a lot of the guess work out of manually coding this. For example, I downloaded the GOP logo used on the GOP's official Twitter account during the 2022 midterm election cycle. `OpenCV` loads the image and converts it to a three-dimensional `numpy` array that contains the BGR (reverse of RGB) values for the pixels in the image. I standardize the image to be 224 $\times$ 224 pixels. The computer is trained to detect the "Republican red" and "Democrat blue" colors. Once trained, the computer detects the pixels that do not contain values within the pre-specified range and converts those pixels to be black. To validate this classification and transformation of the pixels, I include the original image next to the transformed image in @fig-color-detection-example.

```{python}
#| label: example detection
#| echo: false

from sys import path # for path management
from cv2 import imread, imwrite # for color detection
    #* user-defined
#path.append("../")
from PY.helper import colorDetector

# Define colors to detect
    #* White
        #** Not defined. Default for colorDetector()
    #* Red
republican_red = [232, 27, 35] # target color
red_lower = [93, 9, 12] # lower end of spectrum for red
red_higher = [237, 69, 75] # higher end of spectrum for red

# Load gop image to read
img = imread("./assets/img/gop_2022.png")

# Detect colors
percent, img_transformed, result = colorDetector(img = img, color_upper = red_higher, color_lower = red_lower)

transformed= imwrite("../data/temp/study_2/gop_2022_transformed.png", img_transformed) # save transformed image

masked= imwrite("../data/temp/study_2/gop_2022_detected.png", result) # save masked image
```

::: {#fig-color-detection-example layout-ncol="2"}
![Resized original image](../data/temp/study_2/gop_2022_transformed.png){#fig-resized}

![Masked](../data/temp/study_2/gop_2022_detected.png){#fig-masked}

Detecting colors in the GOP logo
:::

I then extract the non-black pixels from my array and calculate the percentage of pixels in the image that are not black.^[$\text{Color} \% = \frac{\text{Non-black}}{\text{Transformed}} \times \frac{\text{Original}_{\text{Height}} + \text{Original}_{\text{Width}}}{2\text{Transformed}_{\text{Height}} + 2\text{Transformed}_{\text{Width}}}$] Summary statistics of these calculated proportions for red and blue are included in the [Appendix](#tbl-yard-sign-summary).

```{python}
#| output: asis
# Print calculated percentage of example
print("For the example in @fig-color-detection-example, about {:.2f}".format(percent) + " of the image is red.")
```

With the data on the proportion of each of the yard signs using the red and blue colors, I merged these data with the MIT Election Lab Data. This left me with data from the House elections between 2018 and 2020. While the data are limited in the number of elections they reflect, they allow me to hold the district composition constant, as redistricting occurs after the Census every 10 years. However, each district and state is different in their laws surrounding elections, and are different in terms of political context. I wanted to examine whether there are meaningful differences between districts that are partisan "strongholds" (Democrats or Republicans tend to get elected in a district) relative to districts that are much less so. To do this, I specify a model that includes an intercept for each state-district unit. Though my outcome of interest (proportion of the yard sign that is red or blue) are continuous (it can take any real number), the outcome is bounded between 0 and 1. While the traditional approach may be to use ordinary least squares, such a technique often can lead to poor model fit, introduce systematic error, and lead to results that are quite unstable. To account for these concerns, I use an ordered beta regression which specifies a link function constraining the conditional distribution of the outcome to be between 0 and 1; as well as inducing cut-points akin to the fractional logistic regression which allows for the outcome to also appear as strictly equal to 0 or 1 [@kubinec_ordered_2022]. Interested readers can find a discussion of how the ordered beta regression compares to other estimators in the beta regression family in [Appendix](#sec-2-a).

Once I fit these models, I used the `marginaleffects` [@arel-bundock_marginaleffects_2022] package to calculate the grand mean of the predicted proportion of the use of the color red or blue for these yard signs, as it correlates with the 5-year rolling average Democratic candidates' vote share. These results are included in @fig-study-2-pred.

```{r}
#| label: fig-study-2-pred
#| layout-ncol: 1
#| fig-cap: More blue on the yard signs in Democratic strongholds
#| fig-subcap:
#|   - Proportion of red
#|   - Proportion of blue
red <- predicted_prob_bar(
  fitted_model = list_fitted[["h_5"]][["red"]]
  , treatment = "Red"
  , hypothesis = "H5"
)
blue <- predicted_prob_bar(
  fitted_model = list_fitted[["h_5"]][["blue"]]
  , treatment = "Blue"
  , hypothesis = "H5"
)
red
blue
```

The results suggest a correlation between districts where Democrats are historically more electorally successful and a lower proportion of red on them. Inversely, those same districts tend to have yard signs with a higher proportion of blue on them. It is important to note that these results are strictly correlational. These results do not claim that campaigns are doing this either because voters are encouraging them to take this strategy, or that they are doing it as a way to proactively get voters to make these associations. Though I do control for unobserved confounds through removing district and year level pooling, there are a number of contextual features that may be unique to that particular district in a particular election year that I do not account for and can threaten claims of causal direction. Though the data available to me limit my ability make a causal claim, these data nonetheless provide evidence consistent with the story I have relayed and the one provided to me in my informal conversations with practitioners.

Determining how political operatives formulate branding strategies for candidates is not the main focus of this story. While it helps me understand how the colors red and blue factor into decisions made on the ground by professional political marketers, like the existing evidence in other research, it does not answer my questions about whether these impressions about voters making these associations exist, nor does it tell me much about the cognitive mechanisms explaining these association. Further, the observational evidence also does not support any causal claim about the electoral ramifications of such processes.

## Study 2

The purpose of [Study 2](#sec-study-2) is to examine whether the color choices on an almost ubiquitous form of campaign branding -- yard signs -- influence people's perceptions of political candidates. Evidence suggests that yard signs *do* matter in shaping political attitudes [@makse_politics_2019], vote intentions [@makse_politics_2019], and even electoral outcomes [@green_effects_2016]. As they are simple, cheap, intrusive, and common forms of campaign branding, they provide a conservative test of the effects of color in campaign branding. 

Using yard signs in this study, I test the first four hypotheses I derived from the snap-judgment model. First, I tested the claim that individuals do indeed notice the color of electoral yard signs. Next, I tested the claim that these colors that individuals detect influence their evaluations of the yard sign and the candidate represented on it. I then tested the claim that the effects on perception are moderated by how consistent the color is with the more complex information displayed on the yard sign. Finally, [Study 2](#study-2) closes with an examination of whether positive information that contains consistency is processed more quickly than negative or inconsistent information. That is, do partisans quickly detect and encode information from a clearly co-partisan political candidate?

### Research design

I recruited participants from Prolific.[^color_influence_pre-reg_anon-3] After providing informed consent to participate in the study, Prolific redirects subjects to Pavlovia,[^color_influence_pre-reg_anon-4] where I provided participants with a demographics and political attitudes questionnaire. Due to concerns about priming effects introduced by these questions as well as concerns of bias introduced by post-treatment control [@montgomery_how_2018], I randomly selected half of the participants to receive the questionnaire post-treatment and the other half receive it pre-treatment. This questionnaire includes common questions about the participant's ascriptive characteristics, and about the participant's political ideology, partisan identification, interest in politics, patriotism, and political knowledge.

[^color_influence_pre-reg_anon-3]: I pay subjects a rate of \$12.00 per hour. On top of the price per participant, Prolific charges a 30% servicing fee.

[^color_influence_pre-reg_anon-4]: Pavolovia allows for researchers to host and run open source experiments for about \$0.20 per participant (to cover their server costs). I use it primarily to integrate the JavaScript components from the jsPsych package [@leeuw_jspsych_2015] for my experimental design.

I included those questions due to expectations that they may act as confounds for my hypotheses. I included some questions collecting information on participants' ascriptive and descriptive characteristics such as age, education, gender identity, and racial identity, as a number of these correlates with partisan identification [see @campbell_american_1969;@mason_uncivil_2018]. Though political knowledge does predict the strength of an individual's partisan identification [@lodge_rationalizing_2013], attention paid to politics is likely a more important confounding variable for my application. The purpose of color in politics is to act as a heuristic for people (a cognitive shortcut). On the one hand, if individuals are aware of the tendency for Republicans to use and be associated with the color red and the degree to which they know factual information about politics is not entirely relevant. On the other hand, those that pay no attention to politics whatsoever may be less likely to be aware of such associations. Additionally, those who express less interest in politics are also likely to identify as more moderate when asked about their ideology and partisan identity [@klar_independent_2016].

Additionally, I included a question about the respondent's sex assigned at birth, and importantly, about whether they have received a diagnosis of *any color blindness*. As some individuals may possess undiagnosed colorblindness, asking about their sex assists in covariate balance. I additionally included an open-ended question asking participants to describe their "first memory of a political event." The use of open-ended questions helps provide an attention check and identify duplicated responses for those spoofing IP addresses with a VPN [@kennedy_strategies_2021].

I then presented participants with an instruction screen informing them of the task for the experiment. In the first trial of the experiment, I randomly presented participants with one of three possible yard signs. These yard signs are simple, with the text "Riley Ready to Lead" and a solid background color of either "Republican red," "Democratic blue," or White.^[See [Appendix](#sec-2-a) to view all of the stimuli used in [Study 1](#study-1).] There is an added component to this, as well as in the other two trials.

Rather than use eye-tracking devices and software, I instead used Mouseview.js [see @anwyl-irvine_mouseviewjs_2022], which either blocks out or blurs a large portion of the participant's screen and encourages them to move their mouse to view different parts of the screen in isolation. As the participants move their cursor around the screen, it tracks the coordinates of the cursor along with the "dwell" time of the cursor in that particular coordinate. One primary benefit of Mouseview.js is that it allows researchers to field their experiments outside of a lab-based setting, while providing results that robustly correlate with the results from a design employing eye-tracking hardware [@anwyl-irvine_mouseviewjs_2022]. This allows researchers to rely less on student convenience samples, which are common with eye-tracking studies. For my design, I am particularly concerned about reliance on a student convenience sample due to variation in participants' ability to detect and process color in the U.S. population. As a result, Mouseview.js enabled me to take advantage of a survey experiment while capturing information about how participants explored the yard signs.

To ensure that participants have a standardized initial placement of their cursor for each trial, I displayed a blank page before viewing the yard sign that requires participants to click a "Next" button. Immediately after clicking "Next," participants were shown the yard sign. The goal is to ensure that variation in where participants explore the image is not dependent on a non-standard starting point for their cursor. 

When viewing each yard sign in each of the three trials, there is a blur over a substantial portion of the screen. At any given point in time, participants can view only 8% of the image without an obstruction, which simulates the observation that we typically foveate on about 8% of our available visual field at any given time [@wedel_review_2008].^[I include a screenshot providing an example of what the participants were able to see with the blur included in the [Appendix](#sec-2-a).] For the obstruction, I utilized a gaussian blur for the overlay of the image, rather than a solid overlay obstructing the participant's view entirely. The gaussian blur allowed participants to see a blurred visual field beyond the cursor. This allowed participants to see enough to take purposeful action to explore blurred parts of the image that attract them [@anwyl-irvine_mouseviewjs_2022]. The use of the gaussian blur required that participants use a web browser other than Safari because of a known issue [@anwyl-irvine_mouseviewjs_2022]. This required participants to either switch browsers or to not participate in the study if they are using Safari at the time they are recruited by Prolific to participate in the study. As this requirement is enforced *before* joining the study, this should not have an effect on the number of excluded participants from my original sample.

Participants move their cursor to explore the yard sign. I alloted 5000 ms to perform the exploration before the image disappears; I did this to encourage a consistent and short duration to explore the image and to formulate an impression of the candidate.^[In marketing research, some studies give participants about 6000 ms in eye-tracking studies to examine a brand and formulate an intention to purchase a product or not [@wedel_review_2008]. With Mouseview.js, a study examining the tool's correlation with optical responses to viewing disgust-and-pleasure evoking images uses 1000 ms; but is intended to be an extended amount of time [@anwyl-irvine_mouseviewjs_2022].] 

After exploring the image in each trial, I asked participants whether they felt that the candidate supposedly owning the yard sign was a Democrat, a Republican, or Neither. After completing the three trials, I asked subjects to indicate their preference among the three signs (one from each trial). 

There are two more trials that are much like the first trial. What is different between the two latter trials and the first is that I varied the amount of color that is on the yard sign. Examples of all of these yard signs are included in the [Appendix](#sec-2-a). For readers interested in the more technical details, the [Appendix](#sec-2-a) accompanying this chapter also includes a table of the data collected in the experiment -- @tbl-study-1-measures; reports full results, posterior predictive checks, and more detailed discussions for all of the models used in the remainder of this section.^[Unless noted otherwise, the reflection of uncertainty in the models are credible intervals at the 90% level. This should not be equated with the frequentist practice of reporting confidence intervals at the 95% level, as credible intervals at this level are often extremely unstable and, more importantly, are interpreted differently. For example, a credible interval at the 90% level can be interpreted as: the probability that the true effect is within that interval, given the data. This interval reflects the degree of uncertainty I have about my point estimate as opposed to being primarily used to interpret levels of statistical significance in a strict null hypothesis test. This contrasts with a confidence interval used in the frequentist framework which is interpreted as: upon repeated samples, 90% of the confidence intervals contain the true effect. To bridge methodological approaches, for those interpreting my credible intervals, I am using two-sided credible intervals here, at the 90% level, the probability that 0 would be the true value given the data would be less than 5% as it would be on one side of my posterior distribution.]

@tbl-study-1-descriptives presents some characteristics of the sample on the whole. The sample is relatively young (mean age of 36.6 years old), and with few reporting having been diagnosed with colorblindness. About 40% of the sample identifies as female, and about 70% of the sample identifies as White (while only 10% report being Hispanic and Black). The average respondent in the sample reports leaning Democratic.

```{r}
#| label: tbl-study-1-descriptives
#| tbl-cap: Descriptive statistics of Prolific sample

df_demographics_subset <- list_df[["cleaned"]][
    , .(
        Age = age
        , `Color blind` = color_blind_dummy
        , Female = female_sex
        , White = white
        , Hispanic = hispanic
        , Black = black
        , `Party ID` = pid_7
    )
] |> 
as.data.frame()

datasummary_skim(
    df_demographics_subset
    , histogram = FALSE
    , notes = c(
      "Data source: Prolific."
      , "Sample characteristics."
    )
    , output = "latex"
)
```

### Do individuals notice color in political branding?

To address this first question, I use a couple of proxy measures for people's attention paid to the yard signs. I collected the first measure through recording the movement of the subjects' cursors along the x-and-y-axes. The second measure accounts for the amount of time participants' cursors linger over a particular coordinate on their screen. Presumably, the more participants explore the yard sign, the more they are finding visual information that they can use to evaluate the candidate. While these two measures are simple proxies and are not direct measures of "noticing the yard sign," they allow for one to get a sense of the patterns by which people explore the yard signs across treatment conditions. This also bolsters my confidence in the degree to which variation between the treatments among different groups of participants is due to actual differences in how people processed these treatments, and not due to random chance.

```{r}
#| label: tbl-h1-trial-1
#| tbl-cap: Average time between cursor movements (Trial 1)
df_movement_trial_1 <- list_df[["cleaned"]][
  , .(
    trial_1_difference_Time
    , trial_1_stimulus
    , trial_1_difference_X
    , trial_1_difference_Y
  )
]
setnames(
  df_movement_trial_1
  , old = c(
    "trial_1_difference_Time"
    , "trial_1_difference_X"
    , "trial_1_difference_Y"
  )
  , new = c(
    "$\\Delta_{t}$ (milliseconds)"
    , "$\\Delta_{x}$ (pixels)"
    , "$\\Delta_{y}$ (pixels)"
  )
)

datasummary_balance(
  ~trial_1_stimulus
  , data = df_movement_trial_1
  , notes = "Data source: Prolific sample."
  , escape = FALSE
  , output = "latex"
)
```

```{r}
#| label: tbl-h1-trial-2
#| tbl-cap: Average time between cursor movements (Trial 2)
df_movement_trial_2 <- list_df[["cleaned"]][
  , .(
    trial_2_difference_Time
    , trial_2_stimulus
    , trial_2_difference_X
    , trial_2_difference_Y
  )
]
setnames(
  df_movement_trial_2
  , old = c(
    "trial_2_difference_Time"
    , "trial_2_difference_X"
    , "trial_2_difference_Y"
  )
  , new = c(
    "$\\Delta_{t}$ (milliseconds)"
    , "$\\Delta_{x}$ (pixels)"
    , "$\\Delta_{y}$ (pixels)"
  )
)
modelsummary::datasummary_balance(
  ~trial_2_stimulus
  , data = df_movement_trial_2
  , notes = "Data source: Prolific sample."
  , escape = FALSE
  , output = "latex"
)
```

```{r}
#| label: tbl-h1-trial-3
#| tbl-cap: Average time between cursor movements (Trial 3)
df_movement_trial_3 <- list_df[["cleaned"]][
  , .(
    trial_3_difference_Time
    , trial_3_stimulus
    , trial_3_difference_X
    , trial_3_difference_Y
  )
]
setnames(
  df_movement_trial_3
  , old = c(
    "trial_3_difference_Time"
    , "trial_3_difference_X"
    , "trial_3_difference_Y"
  )
  , new = c(
    "$\\Delta_{t}$(milliseconds)"
    , "$\\Delta_{x}$ (pixels)"
    , "$\\Delta_{y}$ (pixels)"
  )
)

modelsummary::datasummary_balance(
  ~trial_3_stimulus
  , data = df_movement_trial_3
  , notes = "Data source: Prolific sample."
  , escape = FALSE
  , output = "latex"
)
```

@tbl-h1-trial-1, @tbl-h1-trial-2, and @tbl-h1-trial-3 report the average difference in milliseconds and pixels along the x-and-y-axis of the subjects' screens. These tables demonstrate a few things. First, the average participant in each treatment condition appear to be spending more time exploring the yard signs when there are more "conflicting" colors (trials 2 and 3). Second, we see that, for the most part, the average participant in the red and blue yard sign conditions spend more time exploring those yard signs than the participants viewing the white yard sign.

Overall, it appears that people viewed the yard signs differently depending on which yard sign they were looking at. Now, I turn to exploring how features about the subjects themselves may shape the way that individuals interact and respond to this visual information on the yard signs. The data on the timing and cursor location is much more noisy than I originally anticipated. However, as the tests of the next few questions demonstrate, the evidence supports the general conclusion of the systematic differences between individuals that saw either a red, white, or blue yard sign (despite holding everything else but the color constant).

### Do colors shape perceptions of political objects?

To address the question of whether colors affect perceptions of the candidate and the yard sign, I asked participants to report whether they perceived the candidate to be a partisan -- either a Republican, Democrat, or as non-partisan -- immediately after viewing each image. Everything on the yard sign remains constant except for the color. As representations of ideology are associated with more than just political views, but also things like space [@mills_political_2016] and color [@losada_maestre_color_2022], differences between respondents on the perceived political affiliations of the candidate should be more than "by chance" differences.

I examine differences in respondents' reported perceptions of the candidate's partisan affiliation. Evidence supporting $H_2$ would appear as differences between those who saw the white yard signs and the "partisan color" yard signs in reported perceptions of the partisanship of the candidates. I estimate two multinomial logistic regressions where the main independent variables of interest are two indicator variables for whether respondents received the red yard sign or the blue yard sign in Trial 1.^[In @tbl-hypothesis-2-ordered located in the [Appendix](#sec-2-a) I report the results of these regressions as fitted ordered logistic regressions, rather than multinomial. I come to the same substantive conclusions regardless of whether I fit a multinomial or ordinal logistic regression.] The baseline category for both of these indicator variables is if they instead saw the white yard sign.

@fig-h-2-predictions presents the predicted probabilities of an average subject reporting the candidate as either a Democrat, Independent, or Republican when viewing the different yard signs. The error bars reflect the high density credible interval for 90% of my posterior draws. Each bar reflects the predicted probability of an outcome -- listing the candidate as either a Democrat, Independent, or Republican. When interpreting the error bars, you will want to look at the difference in the error bars *between* yard sign treatments rather than *within* treatment. 

We see that the models indicate substantive and statistically meaningful differences between the yard sign treatments for each outcome. That is, the red and blue yard signs did shift people's perceptions of the partisanship of the candidate relative to the white yard sign. Specifically, the evidence suggests that predicted probability of a subject perceiving the candidate with a red yard sign as a Republican is 70%, whereas it is only about 30% when viewing a white yard sign. The predicted probability that a participant perceived the candidate with the red yard sign as a Democrat is less than 5%. However, when viewing a blue yard sign, the predicted probability that a participant reports the candidate to be a Democrat is at about 50% whereas it is only about 10% if the yard sign is white. As we saw with the association between a Democratic candidate and a red yard sign, we see that the predicted probability that a participant perceived a candidate with a blue yard sign as a Republican is less than 20% and about 45% as an Independent. The full table of results for these models are reported in the [Appendix](#sec-2-a) in @tbl-hypothesis-2-main which contains the rest of the results from these models. 

```{r}
#| label: fig-h-2-predictions
#| layout-nrow: 1
#| fig-cap: The partisanship of candidates change depending on the color of the yard sign
#| fig-subcap:
#|   - Red treatment
#|   - Blue treatment
red <- predicted_prob_bar(
  fitted_model = list_fitted[["h_2"]][["red_multinomial"]]
  , x_axis = "trial_1_red_stimuli"
)
blue <- predicted_prob_bar(
  fitted_model = list_fitted[["h_2"]][["blue_multinomial"]]
  , x_axis = "trial_1_blue_stimuli"
  , treatment = "Blue"
)
red
blue
```

As the consistency by which the parties have used either the color red or blue has increased since the 2000's, I suspected that the age of my subjects may moderate this relationship. That is, the tendency for subjects to label red yard signs as a Republican candidate versus a different color may be stronger for those who are younger as the consistency in branding is the political environment they have been around longer. I expected this particular relationship may be weaker for older subjects as they may place current branding strategies in a larger political context where this was not always the case.

I fit two ordered logistic regressions where the independent variables are indicator variables reporting whether the participant received the red (the first model) or they received the blue treatment (the second model). Those included in the baseline category for both models are those who received the white yard sign treatment. Since I believed that age may moderate this effect, I include an interaction term for both of these models that multiplies these treatment indicator variables with age.

Though my pre-registered expectations were that age would moderate this effect, these models suggest that there are not substantive or statistically meaningful differences in how older and younger participants responded to these treatments. The results of these models included in the [Appendix](#sec-2-a) in [@tbl-hypothesis-2-ordered].

I also explore whether these effects may be weaker for those with colorblindness. The results of this model is reported in [@tbl-colorblindness], which is located in the [Appendix](#sec-2-a). The results do not suggest that they are. However, given that I had a very small number of respondents reporting colorblindness in my sample, the lack of substantive or statistical effects may be due to the fact that I did recruit enough participants with colorblindness in each group to compare. 

I also test whether my effects here are sensitive to my choice to run two separate regression models -- one for each treatment. I fit a single ordered logistic regression with two indicator variables for the treatment coded as: 0 did not receive the red/blue treatment, 1 did receive treatment. The full results of this alternative model specification are included in [@tbl-robustness-alt-specification-h-2]. This means that the intercept term for the regression would be the predicted probability of the average respondent labeling the owner of the yard sign as either Democrat, Independent, or Republican. The conclusions I draw from this regression model do not change the ones I make here with @fig-h-2-predictions.

In summary, I find that subjects perceive candidates with red yard signs as Republican, candidates with blue yard signs as Democratic, and candidates with white yard signs as being neither -- an Independent. However, these yard signs are *very* red and blue. In the next section, I examine how these effects may be weaker when we use less red or blue/include more blue or red. That is, I consider if using both colors on the yard signs has the capacity to increase uncertainty about the perception of partisan affiliation.

### Do these perceptions require consistency between information types?

The design of the latter two trials in the study presents yard signs with mixtures of non-partisan and out-partisan colors. For example, I presented participants with primarily red (and presumably Republican) yard signs, but with some blue or white in them. I pre-registered that the trials that use less "consistent" visual information demonstrate more uncertainty among respondents in their reported perceptions of the candidate's positions. Specifically, I expected that participants would perceive the yard signs that have both red and blue on them as more moderate, and that the higher proportion of the color red or blue among the two colors will lead respondents, on average, to be more likely to believe that the candidate leans more Republican or Democratic, respectively. This is not to say that I expected the results to change significantly, but rather, that the certainty by which I can predict individuals' guesses of the candidate's partisan affiliation will weaken.

I fit four multinomial logistic regression models, two for each trial.^[I also report the results of these four models as ordered logistic regressions in @tbl-hypothesis-2a-ordered and @tbl-hypothesis-2a-cont-ordered which are located in the [Appendix](#sec-2-a).] Each model for the trial calculates whether an average subject in the study reported that the yard sign they saw in the trial was for a Democrat, Independent, or a Republican. The predicted probabilities for each outcome occurring under different treatments and for different trials are presented in @fig-h-2a-predictions. @tbl-hypothesis-2a and @tbl-hypothesis-2a-cont located in the [Appendix](#sec-2-a) reports the full results of these models while @fig-h-2a-ppc located in the [Appendix](#sec-2-a) reports the posterior predictive checks of these models.

```{r}
#| label: fig-h-2a-predictions
#| layout-nrow: 2
#| fig-cap: Mixing red and blue in a yard sign increases uncertainty about partisanship
#| fig-subcap:
#|   - Trial 2 Red treatment
#|   - Trial 2 Blue treatment
#|   - Trial 3 Red treatment
#|   - Trial 3 Blue treatment
plot_trial_2_red <- predicted_prob_bar(
  fitted_model = list_fitted[["h_2a"]][["trial_2_red_multinomial"]]
  , x_axis = "trial_2_red_stimuli"
)
plot_trial_2_blue <- predicted_prob_bar(
  fitted_model = list_fitted[["h_2a"]][["trial_2_blue_multinomial"]]
  , x_axis = "trial_2_blue_stimuli"
  , treatment = "Blue"
)
plot_trial_3_red <- predicted_prob_bar(
  fitted_model = list_fitted[["h_2a"]][["trial_3_red_multinomial"]]
  , x_axis = "trial_3_red_stimuli"
)
plot_trial_3_blue <- predicted_prob_bar(
  fitted_model = list_fitted[["h_2a"]][["trial_3_blue_multinomial"]]
  , x_axis = "trial_3_blue_stimuli"
  , treatment = "Blue"
)
plot_trial_2_red
plot_trial_2_blue
plot_trial_3_red
plot_trial_3_blue
```

The results from these models offer partial support for my pre-registered expectations. First I see that yard signs using less blue are not as distinguishably Democratic as the white yard sign. In other words, voters are not meaningfully more likely to report that the yard sign with less blue on it belongs to a Democratic candidate versus a white and black yard sign. So the strength of using a blue yard sign to communicate alignment with the Democratic party weakens if you use less blue relative to white, or if you include red on it. With red yard signs, however, we see that voters still see them as belonging to Republican candidates, even when we reduce the amount of red on the yard sign and even when we include blue.

One potential reason for this may be the association of the American flag when using all three colors given the Republican party's tendency to condemn those who do not adhere to social norms about showing respect to the American flag. This, however, is untestable based on the design of the study. However, what we do see is that there are bounds by which at least the color blue on a yard sign indicates to voters that the candidate is a Democrat. What remains unclear is whether these perceptions of ownership by a partisan candidate influence people's willingness to support that candidate or express favoritism toward them ($H_3$).

### Does the color of a yard sign explain support for a candidate

An important implication of the snap-judgment model is that if individuals perceive candidates using the color red as Republican while candidates using the color blue as Democratic, that partisans may be more attracted to yard signs displaying the color that fits with these associations. That is, if the color red conveys group membership to the Republican party, we should expect that Republican individuals should like the red yard signs more and be more willing to vote for candidates using those colors in their campaign materials. We should expect a similar thing with Democrats but with blue yard signs. Another expectation is that if color does indeed matter as a form of political communication, we should expect these relationships to be relatively strong, despite little substantive information (e.g., policy positions and name recognition) about the candidate. 

After the three trials, I asked participants which of the candidates for the three yard signs they would vote for. I create an indicator variable from this question that documents whether participants would vote for the candidate that owns the first yard sign (1) or not(0).

I fit two logistic regression models with the vote variable as the outcome I am trying to explain. In the first of the two logistic regression models, I examine whether the effect that receiving a red versus a white stimuli is moderated by the participants' partisanship. As partisanship and its moderating effect on the treatment is of interest here (and partisanship is not being randomly assigned), I control for a number of confounding variables such as attention paid to politics, age, gender identification, and racial identification. The second logistic regression model is much like the first. The difference is that instead of examining the moderated effect of the red treatment, I examine the moderated effect of the blue treatment. As I am still interested in examining how partisan identification modifies the relationship between support for the candidate when comparing a blue versus a white yard sign, I include the same controls as I did with the first logistic regression model. I include the full table of results for both of these models in @tbl-h-3-main ([Appendix](#sec-2-a)).

```{r}
#| label: fig-h-3-predictions
#| layout-nrow: 1
#| fig-cap: Probability of voting for candidate with yard sign
#| fig-subcap:
#|   - Red treatment
#|   - Blue treatment
red <- predicted_prob_bar(
  fitted_model = list_fitted[["h_3"]][["red"]]
  , x_axis = "trial_1_red_stimuli"
  , treatment = "Red"
  , hypothesis = "H3"
  , x_label = "Party ID"
  , y_label = "Pr(Vote for candidate)"
  , legend_title = "Treatment"
)
blue <- predicted_prob_bar(
  fitted_model = list_fitted[["h_3"]][["blue"]]
  , x_axis = "trial_1_blue_stimuli"
  , treatment = "Blue"
  , hypothesis = "H3"
  , x_label = "Party ID"
  , y_label = "Pr(Vote for candidate)"
  , legend_title = "Treatment"
)
red
blue
```

@fig-h-3-predictions presents the average predicted probability of supporting a candidate. The results fit with my pre-registered expectations. First, I see that the predicted probability that a strong Democrat would vote for a candidate with a red yard sign is less than 10% (while for strong republicans it is at about 70%). Likewise, we see that strong Democrats much prefer a candidate with a blue yard sign than a candidate with a white yard sign, 80% relative to 40%, respectively. Strong Republicans are unlikely to vote for a candidate with a blue yard sign and a white yard sign, with their predicted probability of voting for either of those candidates below 30%.

### Do partisans process co-partisan branding faster?

The other analytical tasks do not examine my pre-registered expectations derived from the motivated reasoning portion of the model. That is, do people process in-group information faster than out-group information? There is, of course, evidence of these tendencies in political circumstances [@lodge_rationalizing_2013].

To examine whether my pre-registered expectation that motivated reasoning is also present in the processing of politically-relevant color, I examine the following: the difference in the amount of time between the start of viewing a stimulus and clicking "Next" to stop viewing the stimulus, among those who were viewing a presumed co-partisan yard sign relative to those viewing a presumed out-partisan yard sign. As the outcome is a count of the amount of time participants spent looking at a yard sign, I turn to a class of regression models that work well for explaining outcomes measured as count data.^[By the nature of my measure, I do not believe that participants can record a value of 0 as time elapsed is measured in milliseconds. Additionally, I suspect over-dispersion, as I expect to observe a large bulk of participants recording a very small time elapsed, while for others I expect to record a quite large amount of elapsed time. In the appendix, @tbl-h-4-dispersion summarizes the time elapsed outcome variable; this demonstrates over-dispersion. Given this, rather than using a count model assuming a poisson-distributed outcome, I instead assume an outcome distributed as poisson-gamma.] I therefore fit two poisson-gamma models (also referred to as negative binomial regressions). I am interested in explaining whether time elapsed can comes not only from the color of the yard sign that the subject is viewing, but also whether this effect is moderated by an individual's partisanship. I therefore include an interaction term between stimuli and the partisan identification of the respondent. Like before, as partisan identification is not randomly assigned, I control for confounds such as attention paid to politics, age, gender identity, and racial identity. @tbl-h-4 ([Appendix](#sec-2-a)) presents the full table of results for these two poisson-gamma regression models. @fig-h-4-ppc also indicates that the model does a quite good job at predicting the distribution of the time elapsed outcome variable.

```{r}
#| label: fig-h-4
#| fig-cap: The effect of party congruency on time spent looking at yard sign
#| layout-ncol: 2
#| fig-subcap:
#|   - Red treatment
#|   - Blue treatment

red <- predicted_prob_bar(
  fitted_model = list_fitted[["h_4"]][["red"]]
  , x_axis = "trial_1_red_stimuli"
  , treatment = "Red"
  , hypothesis = "H4"
  , x_label = "Party ID"
  , y_label = "Predicted amount of time elapsed"
  , legend_title = "Treatment"
)
blue <- predicted_prob_bar(
  fitted_model = list_fitted[["h_4"]][["blue"]]
  , x_axis = "trial_1_blue_stimuli"
  , treatment = "Blue"
  , hypothesis = "H4"
  , x_label = "Party ID"
  , y_label = "Predicted amount of time elapsed"
  , legend_title = "Treatment"
)
red
blue
```

@fig-h-4 presents the average predicted elapsed time for participants in different contexts. Overall, these results communicate inconclusive support for my pre-registered expectations on $H_4$ in either regression model. Strong Democrats do not appear to spend more time looking at red yard signs than white ones, but once I account for the variation in the data, I cannot be sure that these differences are not due to random chance. I also observe that there are not really any differences (substantive or statistical) between partisans looking at blue versus white yard signs.

## Conclusions

In this chapter I argue that the colors red and blue provide useful information to voters about politics. Specifically, the colors red and blue provide information about candidates' partisanship. Second, I argue that the information gleaned from these colors can shape how people engage with politics. While I had a number of other expectations this chapter, these were the two primary questions I wanted to address.

Campaigns appear to systematically use the colors red and blue at different rates depending on whether the district is more "up for grabs" or whether it is a partisan stronghold. Specifically, my first study suggests that campaigns use more blue on their yard signs in districts that have a higher vote share for Democrats in the five previous years, and use red much less often in these same circumstances. This fits with the strategies communicated to me by a campaign marketing firm. Another question coming from that conversation and the existing literature was whether voters actually make these associations. 

Evidence from my experiment suggests that the use of the colors red and blue convey partisan information, while a third color like white provides very little useful political information. The experiment provides evidence that individuals see candidates that use red on a yard sign as more Republican and candidates that use blue as more Democratic. Evidence from the experiment also suggests that using less of those partisan colors and using both colors makes it a bit harder for individuals to make partisan associations. Further, the experiment demonstrates that these associations that we make with color and partisanship are powerful enough that they can shape whether people express a willingness to vote for a candidate. That is, individuals that identify with the Republican party are much more likely to vote for a candidate with a red yard sign than a white yard sign, and Democrats are much more likely to vote for a candidate with a blue yard sign than yard signs with other colors.

Having established some baseline findings, in the next chapter I examine whether the snap-judgment model holds up in more complex settings. Specifically, I next move to consider whether color can shape how we have conversations about politics with others, as well as the degree to which color can be a tool inhibiting political persuasion.

# References

::: {#refs}

:::

{{< include appendix.qmd >}}